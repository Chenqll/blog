# 一些遇到的接口
- einsum 爱因斯坦求和

    爱因斯坦简记法：是一种由爱因斯坦提出的，对向量、矩阵、张量的求和运算 $\sum$ 的求和简记法。

    在该简记法当中，省略掉的部分是：1）求和符号 $\sum$ 与2）求和号的下标 i 

    省略规则为：默认成对出现的下标（如下例1中的i和例2中的k）为求和下标。

    比如用 $x_i$ , $y_i$ 简化表示内积<X,Y>

    ```python
    print(a_tensor)
 
    tensor([[11, 12, 13, 14],
            [21, 22, 23, 24],
            [31, 32, 33, 34],
            [41, 42, 43, 44]])
 
    print(b_tensor)
    
    tensor([[1, 1, 1, 1],
            [2, 2, 2, 2],
            [3, 3, 3, 3],
            [4, 4, 4, 4]])
    
    # 'ik, kj -> ij'语义解释如下：
    # 输入a_tensor: 2维数组，下标为ik,
    # 输入b_tensor: 2维数组，下标为kj,
    # 输出output：2维数组，下标为ij。
    # 隐含语义：输入a,b下标中相同的k，是求和的下标，对应上面的例子2的公式
    output = torch.einsum('ik, kj -> ij', a_tensor, b_tensor)
    ```
- sampler 采样器

    https://blog.csdn.net/aiwanghuan5017/article/details/102147825
  
    首先需要知道的是所有的采样器都继承自Sampler这个类，如下：

    可以看到主要有三种方法：分别是：

    __init__: 这个很好理解，就是初始化
    __iter__: 这个是用来产生迭代索引值的，也就是指定每个step需要读取哪些数据
    __len__: 这个是用来返回每次迭代器的长度

    **SequentialSampler** 按顺序对数据集采样。其原理是首先在初始化的时候拿到数据集data_source，之后在__iter__方法中首先得到一个和data_source一样长度的range可迭代器。每次只会返回一个索引值。

