# few_shot
# 疑问？？
    - 分布式系统和少样本学习是否能够利用各自的优点 将特征提取和数据传输的优点最大化和结合
    - 深度学习的成功很大程度依赖于大量训练数据，而在真实世界中

# Few Shot learning
- [1.基于模型微调](#1.基于模型微调)
- [2.基于数据增强](#2.基于数据增强)
- [3.基于迁移学习](#3.基于迁移学习)
|  分类   | 优点  |  缺点  |
|  ----  | ----  | -----  |
| 基于模型微调  | 操作简单，只需要调整部分参数 |  源域和目前与之间差距大时，容易出现过拟合|
| 基于数据增强.基于无标注数据  | 不需要调整模型，只需要利用辅助数据扩充数据集或者增强数据特征  |容易引入噪声|
| 基于数据增强.基于数据合成|同上|同上|
| 基于数据增强.基于特征增强|同上|同上|
|基于迁移学习.基于度量学习|便于计算|过于简单|
|基于迁移学习.基于元学习| 具有学习能力| 复杂度较高，刚兴起|
|基于迁移学习.基于图神经网络|性能，可解释性，直观|样本数变多后，边的数量也会变多，导致复杂度增加|

## 1.基于模型微调
- 通用微调语言模型 universal language model fune-tuning[(ULMFit)](#1.1 ulmfit)

### 1.1 ULMFit
- 创新点---通过改变学习速率来微调语言模型：
  - 模型底层的普遍特征需要用到较慢的学习速率--以便于学到稳定的底层特征
  - 高层特征则需要用更大的学习速率学习
## 2.基于数据增强
- 是利用辅助数据集或辅助信息增强目标数据集中样本的特征或扩充目标数据集，使模型能够更好的提取特征。
- 通过数据增强提高样本多样性
- [2.1基于无标签数据](#2.1基于无标签数据)
- [2.2基于数据合成](#2.2基于数据合成)
- [2.3基于特征增强](#2.3基于数据增强)
### 2.1基于无标签数据
- 是指利用无标签数据对小样本数据集进行扩充，常用方法：
  - **2.1.1半监督学习** - MAML
  - [2.1.2直推式学习](#2.1.2直推式学习)
#### 2.1.2直推式学习
- 半监督学习的子问题，分为四个步骤：
  - 特征嵌入--输入有标签和无标签数据，映射到向量空间中
  - 图构建-- 主要是算无标签数据和有标签数据的相似度，以便于后面的标签传播。
  - 标签传播
  - 损失计算
### 2.2基于数据合成
- 为小样本合成新的数据来扩充数据列，常用GAN
### 2.3基于特征增强
- 通过增强样本特征空间提高样本多样性
- 双向网络 **TriNet** 通过标签语义空间和图像特征空间的相互映射，对图像特征进行增强。---解码器，Transformer。
## 3.基于迁移学习
- wang提出了回归网络，他们通过训练回归网络**T**（他们所认为的 一个有少量样本训练得到的模型和大量样本训练的模型之间存在一个通用的忽略类别的转换**T**）
- [3.1基于度量学习](#3.1基于度量学习)
- [3.2基于元学习](#32基于元学习)
- [3.3基于图神经网络](#3.3基于图神经网络)
### 3.1基于度量学习
- 度量==距离，故度量学习也称为相似度学习
- 具有两个模块：嵌入模块 embedding 和度量模块 counting 。
- 孪生神经网络（siamese nn），通过输入样本对，最大化不同类别的损失和最小化相同类别的损失的两个CNN网络
- [3.1.1原型网络](#3.1.1原型网络)
- 匹配网络
#### 3.1.1原型网络
- 作者认为每个类别在向量空间中都存在一个原型，也称为类别中心点，通过最小化相同类别与中心点的距离，和最大化不同类别与中心点的距离
- 通过结合半监督学习的方法，引入大量非标注数据，改善分类边界。
- 引入半监督学习的原型网络：
  - 无标注数据均属于带标签数据的类别，此时将两类数据一起输入原型网络即可
  - 无标注数据有一部分干扰类，解决方法是将干扰类的原点设为（0，0），学习干扰类的半径
  - 基于对干扰类的优化（不可能所有的干扰类都属于同一类，同属于同一个原型），无标注数据masked变形被提出。
  - **masked？？？？？？？**
### 3.2基于元学习
- 让模型获得一种学习能力，这种学习能力可以让模型自动学习到一些元知识，比如超参数等。
### 3.3基于图神经网络
**1、图神经网络**   